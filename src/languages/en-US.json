{
    "home": "Home",
    "project-title": "Projects",
    "about-title": "About",
    "contact-title": "Contact",
    "about-content-aboutme-old":"I am SU YI XIANG, currently working as an engineer in the Digital Experience Development Department at AUO Company. My expertise lies HCI, VR/AR development, and front-end interface design and implementation. I aspire to maintain an open and creative mindset in my design work, continuously learn new knowledge, and deepen my skills. I strive to objectively analyze data and technological trends, implement solutions, and ensure execution efficiency to face various unknowns and challenges in life.",
    "about-content-aboutme":"I’m Sean Su, a multidisciplinary developer with expertise in human-computer interaction, AR/VR (XR), Unity development, frontend engineering, and UI/UX design. I specialize in building immersive and interactive systems, with practical experience in AI integration, Digital Twins, and real-time data visualization. Committed to continuous learning and technical depth, I adopt a data-informed and systems-thinking approach to solve complex problems. I focus on bridging emerging technologies with practical applications—transforming innovative ideas into executable, scalable solutions in dynamic environments.",
    "about-content-education-01":"National Cheng Kung University Master’s degree , Sep 2019 - Feb 2022",
    "about-content-education-02":"National Kyushu University Master’s Exchange , Sep 2021 - Jan 2022",
    "about-content-education-03":"National Kaohsiung Normal University Bachelor’s degree , Sep 2016 - Jun 2019",
    "about-content-experience-01":"Software Engineer, Digital Experience Development Department, AUO, Mar 2022 - Mar 2025",
    "about-content-experience-02":"Project Research Assistant, National Cheng Kung University, Sep 2020 - Jun 2021",
    "about-content-experience-03":"Intern, Product Design, 25TOGO Design, Jul 2018 - Aug 2018",
    "about-content-experience-04":"Senior Software Engineer, Digital Twin Technology Department, Delta Electronics, Mar 2025 - Now",
    "about-content-education-01-content-01":"Ergonomics & Interaction Design Lab",
    "about-content-education-01-content-02":"Thesis: 360° Real Scene-Based Virtual Reality to Enhance Motivation for Elderly to Use the Lower Limb Pedaling Device",
    "about-content-education-02-content-01":"Computer Graphics Design Lab ( Matsuguma Hiroyuki )",
    "about-content-education-02-content-02":"Paper: Development of ‘’Kuchipa’’ a game of mouth exercises for children with dysarthria ",
    "about-content-education-03-content-01":"Department of Industrial Design",
    "about-content-education-03-content-02":"Graduation Project: Rescuer - Golden Pin Concept Design Award shortlisted ",
    "about-content-experience-01-content-01":"Developed AR scenario applications for AUO’s internal manufacturing environments (e.g., Unity, HoloLens, Digital Twins, MRTK)",
    "about-content-experience-01-content-02":"Researched and implemented emerging technologies and applications (e.g., XR, Avatar, Edge AI, GAI)",
    "about-content-experience-01-content-03":"Smart AUO Exhibition Web UIUX Design & Front-end",
    "about-content-experience-01-content-04":"Full-stack development for internal R&D system projects in factory settings",
    "about-content-experience-02-content-01":"Project: Establishment of Intelligent Healthcare Ecosystem for Senior Adults",
    "about-content-experience-02-content-02":"Cross-field collaboration with the Department of Medical Engineering and History for interactive device design",
    "about-content-experience-03-content-01":"Origami bag sports style design",
    "about-content-experience-03-content-02":"Origami mobile phone shell series design",
    "about-content-experience-04-content-01":"Developed Digital Twin applications for manufacturing environments",
    "project1-subtitle":"Smart Factory AR Application",
    "project1-brief":"FabAR is a system that uses factory inspections and route guidance as simulation scenarios. It includes components such as chart display, data integration, and QR code display positioning required in the simulation scenario. The purpose is to allow secondary developers in the company to develop using various components through simple operations and quickly deploy them to Hololens or Android applications.",
    "project1-review-content1":"FabAR is primarily based on the Unity environment, creating various AR application components for Fab applications. This allows secondary developers to develop by simply operating our packaged components and then deploy them for use on Hololens. FabAR has developed components such as QR code, UI, IOT, Web Browser, etc., allowing users to download according to their needs and carry out subsequent development work according to various application scenarios.",
    "project1-feature-subtitle1":"Factory Inspection",
    "project1-feature-content1":"Users can scan QR codes to monitor machine information and freely drag information panels to their desired positions. When there is abnormal machine information, users can open the machine repair guide to assist in inspection. If further operational guidance is needed, users can access the Guides App to browse pre-edited guides for instructions or data.",
    "project1-feature-subtitle2":"Route Guidance",
    "project1-feature-content2":"Users perform secondary development through the developed component. Use route guidance as a simulation scenario. After dragging and dropping arrows, labels, machine information, and other objects to designated positions, save them to complete the planning of route guidance.",
    "project4-subtitle":"Realistic panoramic video-style virtual reality combined with lower limb stepping device system",
    "project4-brief":"V-Bike is a cycling device system designed for elderly users, incorporating physiological data, training courses, and 360-degree real panoramic video virtual reality technology. With simple operation, even seniors in hospital rooms or indoor settings can use V-Bike to travel to different scenic spots and foreign locations. While pedaling, they can enjoy the local 360-degree scenery, turning training into a delightful journey.",
    "project4-feature-content1":"V-Bike primarily offers two modes of playback media: head-mounted displays and screens, allowing users to freely choose their preferred way to exercise. We integrate panoramic video content shot into Unity for a mixed reality system, designing interfaces and workout processes suitable for users through visual and intuitive operations.",
    "project4-feature-content2":"During the pilot test, both screens and head-mounted displays were used for elderly users. For the head-mounted displays, seniors often felt dizzy, discomfort from pressing against their glasses, a slightly hazy screen, and difficulty adjusting the focal length to a comfortable distance, leading them to stop the activity after about 1 minute. In contrast, each participant spent over 4 minutes using the screen and found it more comfortable for viewing while pedaling. They also enjoyed reminiscing about or comparing differences in places they had visited before based on the screen content, and they liked the idea of exercising while viewing their favorite historical sites. Therefore, it was understood that elderly users prefer using screens for a realistic panoramic video virtual reality experience combined with pedaling devices over head-mounted displays.",
    "project4-design-content1":"V-Bike targets elderly users as its primary users, considering each step of operation by elderly users to prompt function changes or status updates, enabling immediate feedback upon completing an action to increase interactivity. Through a series of design methods such as Functional Map and Flow Chart, the user process steps are used as the starting and ending points of the flow, considering how elderly users use controllers to change screen states in the design process, serving as a guideline for subsequent programming and implementation.",
    "project4-design-content2":"The controller is designed with simplicity and minimal operation buttons for hardware and circuit design, featuring only buttons for confirmation and cancellation, along with a joystick for viewing panoramic videos. It is placed in the middle of the handlebars for easy operation by elderly users and communicates commands to the V-Bike system via Bluetooth. It also includes QR code login functionality, allowing elderly users to easily scan a card with one hand. Additionally, there is blank space available for users to write their name or ID number, ensuring they do not mistake cards when picking them up.",
    "project4-experiment-content1":"V-Bike conducted a two-month test in the Dongguo Community in Chiayi to understand the motivation and effectiveness of using the pedal device with real panoramic video virtual reality for elderly users. During the experiment, the system's interaction with elderly users in the community was recorded to assess whether it meets the community's needs and the willingness of elderly users, their relatives, and caregivers to use it, serving as the basis for future evaluations. The participants were elderly individuals aged 65 and above, with a total of 10 participants. These elderly participants had never used the V-Bike system before the experiment and were assessed as having normal cognition through the MMSE cognitive assessment scale. They also had to engage in activities in the field long-term and were excluded if they had severe lower limb injuries preventing them from participating in the experiment, or if they had impaired vision or hearing preventing them from participating.",
    "project4-experiment-content2":"In the testing process, we collect relevant physiological data from elderly users, such as: (1) Pedal revolutions: recording the number of pedal revolutions each time elderly users use the information version and the scenic version, to compare whether there are changes in the users before and after testing and the reasons for them; (2) Pedal speed: recording the pedal speed each time elderly users use the information version and the scenic version, by dividing the comprehensive pedal speed measured per second by the pedal time, to understand whether there are differences in the lower limb abilities of the users between the information version and the scenic version; (3) Average heart rate: dividing the sum of heart rates during each pedal process by the pedal time, as a reference for measuring the users' exercise ability during pedaling; (4) Pedal count: to ensure that the number of times elderly users use it is sufficient and with minimal differences, without affecting their motivation. Pedal revolutions, pedal speed, and average heart rate are recorded in real-time and then organized through averaging.",
    "project4-experiment-content3":"After two months of testing, we believe that elderly users feel a stronger sense of actually being at the location when watching real panoramic videos. To enhance their long-term use of the immersive experience brought by real panoramic videos, we propose using virtual guides, such as levels or arrow indicators, to guide them in 360-degree viewing, increasing their understanding of the content. Regarding the system content, we suggest increasing the number of real panoramic videos to over 10 to provide more choices for elderly users. We also recommend combining audiovisual guided scenic content with game level design to further engage elderly users in the interactive system. Currently, the integration of real panoramic videos with virtual reality and pedaling devices has only been tested in community settings and has not been tested in day care centers and other facilities. However, we believe that implementing it in day care centers is feasible. In the future, we will follow the recommendations in this article for adjustments and conduct additional experiments and field tests, hoping that this design can truly be applied in the field to help more elderly users stay motivated during their lengthy training and improve lower limb health.",
    "project5-subtitle":"Designing Training for Children's Pronunciation Mouth Shapes Using Image Recognition",
    "project5-brief":"The Kuchipa project utilizes interactive design and production to assist children in learning pronunciation and avoiding articulation disorders. One of its interactions, びいいいいむ, primarily uses facial recognition to detect the child's mouth shape. It employs lasers emitted from the mouth to attack monsters, enabling children to maintain their mouth shape through an engaging game and train the muscles around their mouths.",
    "project5-feature-content1":"The Kuchipa project is a collaboration with the Graduate School of Art and Engineering at Kyushu University. Due to the pandemic, discussions and execution of the project are conducted online.",
    "project5-feature-content2":"Speech sound disorders often refer to abnormalities in oral structures and neurological functions during the articulation process. These abnormalities can result in errors in articulation position, airflow direction, force, speed, and coordination of oral movements, leading to speech errors and alterations. This can cause the produced speech to be incomplete, less clear, and often related to factors such as poor speech perception, lack of coordination in oral movements, speaking habits, and simple learning errors.",
    "project5-feature-content3":"In Japan, children often face the following common pronunciation issues: Unclear pronunciation of the カ (ka), サ (sa), and タ (ta) rows. For example: カラスがいる！ (There's a crow!) Children often mispronounce it as タラス (tarasu). Speaking in a baby-like manner. For example: 猫がたくさんいた！ (There were many cats!) Pronunciation often becomes タクチャン (takuchan). Unclear pronunciation leading to difficulties in understanding what the child is saying.",
    "project5-feature-content4":"In reality, parents often feel stressed due to their children's articulation disorders. Parents hope that their children can achieve a state without pronunciation barriers before the age of 6, as this is a critical period for language development. However, it is found through visits that some children find it difficult to achieve this. Since hospitals are open until 5:00 PM, parents and children are usually at work or school during that time. Some children cannot receive training at hospitals due to school reasons, so providing services that can be conducted at home is essential. With ongoing advancements in acoustic analysis and artificial intelligence technology, we aim to create games that can build the foundation of articulation, meeting the needs for training at the hospital, at home, and in clinic waiting rooms. This helps children establish a strong foundation in articulation, preventing mislearning and reducing parental stress.",
    "project5-feature-content5":"The target audience for Kuchipa is mainly children aged 4-6 years old, with a maximum daily training time of about 10 minutes. The goal is to achieve training effectiveness through playfulness and ensure easy understanding of the game's content.",
    "project5-feature-content6":"We quickly developed a functional model for use in clinics by children and doctors for an interactive experience. Doctors believe that combining mouth recognition with game design is a suitable and in-demand software for training children's mouth shapes, as it helps them focus better. Children also enjoy moving their mouths to complete levels within the game. In the end, we designed 'びいいいいむ,' a software that uses facial recognition to detect children's mouth shapes. Through shooting lasers from the mouth to attack monsters, children can maintain their mouth shapes through an engaging game, effectively training the muscles around their mouths.",
    "project5-future-content1":"The games currently being developed involve controlling large mouth movements. It is hoped that finer control can be achieved through recognition in the future. The plan is to continue developing models used in target scenarios and combine the four games currently being developed into one application for easier user testing and related experiments.",
    "project5-future-content2":"In the future, we hope to design games that fit into three scenarios: during consultations, at home, and in waiting rooms. This is to facilitate operation and use by doctors, parents, and children. We also plan to allow children to draw and scan their artwork into the game to enhance the connection between the game and children."
}